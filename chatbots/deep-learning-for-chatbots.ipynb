{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Learning for Chatbots\n",
    "\n",
    "http://www.wildml.com/2016/04/deep-learning-for-chatbots-part-1-introduction\n",
    "\n",
    "Taxonomy of models\n",
    "\n",
    "Retrieval-based vs Generative Models\n",
    "\n",
    "Retrieval-based models (easier) use a repository of predefined responses and some kind of heuristic to pick an appropriate response based on input an context.  The heuristic can be as simple as a rule-based expression match, or as complex as an ensemble of Machine Learning classifiers.  These systems don't generate any new text; they just pick a response from a fixed set.\n",
    "\n",
    "Generative models (harder) don't rely on pre-defined responses.  They generate new responses from scratch.  Generative models don't rely on pre-defined responses.  They generate new responses from scratch.  Generative models are typically based on Machine Translation techniques, but instead of translating from one language to another, we 'translate' from an input to an output (response).\n",
    "\n",
    "\n",
    "![](http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2016/04/nct-seq2seq.png)\n",
    "\n",
    "Due to handcrafted responses, retrieval-based methods don't make grammatical mistakes, but may be unable to handle unseen cases for which no appropriate predefined response exists.  They can't refer back to contexual entity info like names mentioned earlier in the conversation.\n",
    "\n",
    "Generative models are 'smarter.'  They can refer back to entities in the input and give the impression that you're talking to a human.  But these models are hard to train, are  likely to make grammatical mistakes (esp longer sentences) and require huge amounts of training data.\n",
    "\n",
    "DL can be used for both kinds of models but research is focused in generative models. \n",
    "\n",
    "DL architectures like seq2seq are uniquely suited for generating text.  \n",
    "\n",
    "Production systems are more likely to be retrieval-based for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Long vs Short Conversations\n",
    "\n",
    "Longer conversations are more difficult to automate\n",
    "\n",
    "Short-text conversations (easier) create single response to single input\n",
    "eg, specific question -> appropriate answer\n",
    "\n",
    "Long conversations (harder) go through multiple turns and need to keep track of what has been said.\n",
    "eg, customer support with multiple questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open Domain vs Closed Domain\n",
    "\n",
    "In an open domain setting (harder) the user can take the conversation anywhere.  Not necessarily well-defined goal or intention (eg, twitter, reddit).  The infinite # of topics and certain amount of world knowledge is required to create reasonable responses make this hard.\n",
    "\n",
    "In a closed domain (easier) setting the space of possible inputs and outputs is somewhat limited because the system is trying to achieve a very specific goal.  Technical Customer Support or Shopping Assistants are examples of closed domain problems.  These systems don't need to be able to talk about politics, they just need to fulfill their specific task as efficiently as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common Challenges\n",
    "\n",
    "Incorporating Context\n",
    "\n",
    "To produce sensible responses may need to incorporate both linguistic context and physical context. In long dialogs, people keep track of what has been said and what info has been exchanged: linguistic context.\n",
    "\n",
    "The most common approach is to embed the conversation into a vector, but doing that with long conversations is challenging.\n",
    "\n",
    "Experiments: \n",
    "- Generative Hierarchical Neural Network Models\n",
    "- Attention with Intention for a Neural Network Conversation Model\n",
    "\n",
    "One may also need to incorporate other kinds of contexual data such as date / time, location, or info about a user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coherent Personality\n",
    "\n",
    "When generating responses, the agent should ideally produce consistent answers to semantically identical inputs\n",
    "\n",
    "- How old are you?\n",
    "- What is your age?\n",
    "\n",
    "Sounds simple, but incorporating such fixed knowledge or 'personality' into models is still research-y\n",
    "\n",
    "Many systems learn to generate linguistic plausible responses, but they are not trained to generate semantically consistent ones.\n",
    "\n",
    "Usually that's because they are trained on a lot of data from multiple different users.\n",
    "\n",
    "Models like that (Persona-Based Neural Conversation Model) are making first steps into the direction of explicitly modeling a personality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of Models\n",
    "\n",
    "Ideal way to evaluate a conversational agent is to measure whether or not it is fulfilling its task, eg solve a customer support problem in a given conversation.\n",
    "\n",
    "But such labels are expensive to obtain because they require human judgement and evaluation.\n",
    "\n",
    "Sometimes -- there is no well-defined goal, as in the case of open-domain models.\n",
    "\n",
    "Common metrics (BLEU) for machine translation are based on text matching aren't well-suited because sensible responses can contain completely different words or phrases.\n",
    "\n",
    "Researchers find that none of the commonly used metrics really correlate with human judgement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intention and Diversity\n",
    "\n",
    "A common problem with generative systems is that they tend to produce generic responses like “That’s great!” or “I don’t know” that work for a lot of input cases. Early versions of Google’s Smart Reply tended to respond with “I love you” to almost anything. That’s partly a result of how these systems are trained, both in terms of data and in terms of actual training objective/algorithm. Some researchers have tried to artificially promote diversity through various objective functions. However, humans typically produce responses that are specific to the input and carry an intention. Because generative systems (and particularly open-domain systems) aren’t trained to have specific intentions they lack this kind of diversity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well does it actually work?\n",
    "\n",
    "A retrieval-based open domain system is obviously impossible because you can never handcraft enough responses to cover all cases. A generative open-domain system is almost Artificial General Intelligence (AGI) because it needs to handle all possible scenarios. We’re very far away from that as well (but a lot of research is going on in that area).\n",
    "\n",
    "Most of the value of deep learning today is in narrow domains where you can get a lot of data. \n",
    "\n",
    "Here’s one example of something it cannot do: have a meaningful conversation. There are demos, and if you cherry-pick the conversation, it looks like it’s having a meaningful conversation, but if you actually try it yourself, it quickly goes off the rails.\n",
    "\n",
    "Many companies start off by outsourcing their conversations to human workers and promise that they can “automate” it once they’ve collected enough data.\n",
    "\n",
    "That’s likely to happen only if they are operating in a pretty narrow domain – like a chat interface to call an Uber for example. Anything that’s a bit more open domain (like sales emails) is beyond what we can currently do. However, we can also use these systems to assist human workers by proposing and correcting responses. That’s much more feasible.\n",
    "\n",
    "Grammatical mistakes in production systems are very costly and may drive away users. That’s why most systems are probably best off using retrieval-based methods that are free of grammatical errors and offensive responses.\n",
    "\n",
    "If companies can somehow get their hands on huge amounts of data then generative models become feasible – but they must be assisted by other techniques to prevent them from going off the rails like Microsoft’s Tay did.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
